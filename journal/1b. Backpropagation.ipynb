{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325bbd80",
   "metadata": {},
   "source": [
    "# 1b. Backpropagation\n",
    "\n",
    "So I spent the past week and a half convincing myself that I understand the math behind backpropagation, and now I'm going to first prove it all over again here, and then implement it for my baby neural net, so that I can start training it. \n",
    "\n",
    "I'm following along with [Nielsen Chapter 2](http://neuralnetworksanddeeplearning.com/chap2.html), which I really can't praise highly enough - if you don't currently have access to an ML professor who can walk you through the math in person, this chapter is a good substitute. Now that I've gone through it several times and written out my own proofs of various parts, I'm going to try to explain/implement this without referring back to the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75542b6",
   "metadata": {},
   "source": [
    "### A brief refresher on gradient descent\n",
    "\n",
    "The basic idea behind training a neural net is that we start with random weights and biases, and want to move towards values for the weights and biases that give us the best performance on our set of training data. Let's unpack this:\n",
    "* __training data:__ this is supervised learning; we've got a bunch of input values along with the expected outputs, and we're trying to have the net arrive at some generalized relationship between them that will hold true for new data. In practice, there are a lot different methodologies for how to use your training data, which I'll get into in more detail in the next journal when I actually start training my neural net.\n",
    "* __performance:__ some measure of how well the net does relative to the expected outputs of the training data -  how frequently is it right (on a classification-type problem), how close is it on average (on an estimation-type problem), etc. Performance on a training set is measured by some cost function that aggregates from performance on each example.\n",
    "* __best:__ not necessarily 100% accurate (since that's probably overfitting and won't generalize well), but reasonably good, depending on what problem we're dealing with and how accurate we need to be.\n",
    "* __move towards values for the weights and biases:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ecb28",
   "metadata": {},
   "source": [
    "### Notation\n",
    "\n",
    "To start off:\n",
    "* A particular layer of a neural net will be denoted as $l$. $l-1$, $l+1$, etc. refer to the layers before or after layer $l$, and $L$ denotes the final (output) layer.\n",
    "* Assuming we've passed some value through the net, $a_j^l$ is the activation value of the $j$th neuron in layer $l$ (the output of the activation function). $z_j^l$ is the pre-activation value, that is, the weighted sum of the inputs from the previous layer plus the bias (so $a_j^l = \\sigma(z_j^l)$ where $\\sigma$ is that neuron's activation function. We can also refer to $a^l$, $b^l$, or $z^l$ to denote the vector of the given quantities for layer $l$ (e.g. $a^l = [a_0^l, ..., a_n^l]$, where layer $l$ has $n$ neurons total).\n",
    "* $w_{jk}^l$ is the current weight from neuron $k$ in layer $l-1$ to neuron $j$ in layer $l$ (i.e. $w_{jk}^l$ is the weight *to* $j$ *from* $k$. (This is backwards for reasons that make more sense when you think of a neural net as a list of weight matrices and bias vectors,  but we'll use this convention to abide by historical precedent.) $b_j^l$ is the current bias for neuron $j$ in layer $l$.\n",
    "\n",
    "To train a neural net, we have some set of input values that are paired with the corresponding desired output values. We also have a cost function of some kind that provides a measure of the difference between the desired output and the actual output of the neural net.\n",
    "\n",
    "* If our net has $n$ neurons in the input layer and $m$ in the output layer, then $(x, y)$ is a training example, where $x$ is a vector of length $n$ and $y$ is a vector of length $m$.\n",
    "* If we feed a training input $x$ through the network, we get some output vector $a^L$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49556c",
   "metadata": {},
   "source": [
    "### The cost function\n",
    "\n",
    "Our set of training examples is fixed; we're trying to change all the weights and biases in the network so that overall, $a^L$ for each $x$ is pretty close to the corresponding $y$. So at a high level, think of the cost function as something that takes a bunch of candidate values for each weight and bias, applies those weights and biases to each training example, and outputs some measure of the cumulative cost. We want to find some particular set of weights and biases that minimizes the cumulative cost. Our cost function is not a function $C(y, a^L)$ for particular examples; it's more like a function $C_T(w^L, w^{L-1}, ..., w^0, b^L, b^{L-1}, ..., b^0)$, parameterized by the training set $T$ and varying over the weights and biases. This is why it makes sense to talk about minimizing the cost by changing them - it's a function of those quantities and we can do calculus to it.\n",
    "\n",
    "The overall cost function $C$ measures some cumulative error over a bunch of training examples. For backpropagation, though, we want to be able to see how the net processes individual examples, so we can figure out how the net needs to change to better suit each one. So we want our overall cost function to be easily decomposable into a cost function for a particular example - call this $C_x$. So without explicitly defining our cost function, we're going to impose a few restrictions on it:\n",
    "\n",
    "* $C_T(w, b) = \\frac{\\epsilon}{|{T}|}\\sum_{(x, y) \\in T}C_x(w, b)$, that is, for a particular combo of weights and biases, $C_T$ is the average of individual errors $C_x$ over all pairs in the training set, maybe scaled by some constant $\\epsilon$ depending on the exact form.\n",
    "* $C_x(w, b)$ should be easily differentiable. We want to minimize $C_T$, which means we're going to be taking derivatives with respect to each weight and bias, and in this form the derivative of  $C_T$ works out to the (scaled) average of the derivatives of all the individual $C_x$s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e413e67",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
