{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325bbd80",
   "metadata": {},
   "source": [
    "# 1b. Backpropagation\n",
    "\n",
    "So I spent the past week and a half convincing myself that I understand the math behind backpropagation, and now I'm going to first prove it all over again here, and then implement it for my baby neural net, so that I can start training it. \n",
    "\n",
    "I'm following along with [Nielsen Chapter 2](http://neuralnetworksanddeeplearning.com/chap2.html), which I really can't praise highly enough - if you don't currently have access to an ML professor who can walk you through the math in person, this chapter is a good substitute. Now that I've gone through it several times and written out my own proofs of various parts, I'm going to try to explain/implement this without referring back to the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67408db",
   "metadata": {},
   "source": [
    "### A brief refresher on gradient descent\n",
    "\n",
    "The basic idea behind training a neural net is that we start with random weights and biases, and want to move towards values for the weights and biases that give us the best performance on our set of training data. Let's unpack this:\n",
    "* __training data:__ this is supervised learning; we've got a bunch of input values along with the expected outputs, and we're trying to have the net arrive at some generalized relationship between them that will hold true for new data. In practice, there are a lot different methodologies for how to use your training data, which I'll get into in more detail in the next journal when I actually start training my neural net.\n",
    "* __performance:__ some measure of how well the net does relative to the expected outputs of the training data -  how frequently is it right (on a classification-type problem), how close is it on average (on an estimation-type problem), etc. Performance on a training set is measured by some cost function that aggregates from performance on each example.\n",
    "* __best:__ not necessarily 100% accurate (since that's probably overfitting and won't generalize well), but reasonably good, depending on what problem we're dealing with and how accurate we need to be.\n",
    "* __move towards values for the weights and biases:__ we're trying to minimize the cost function, that is, find the set of weights and biases that produces the minimum cost for our training data. However, there's not a simple closed-form expression that lets us directly calculate the weights and biases that will lead to a global minimum - there are dozens of weight/bias variables involved even in a small neural net. What we can do instead is find the derivative at our current set of weights and biases, in the form of a partial derivative for each weight and bias individually. Then, assuming the cost function is reasonably well-behaved, we can take a small step \"downhill\" for each variable, which should bring us a bit closer overall to a minimum (and a global minimum if we're very lucky, but that doesn't really matter). The general method at work here is gradient descent; backpropagation is an algorithm for efficiently calculating the necessary gradient for a neural net."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ecb28",
   "metadata": {},
   "source": [
    "### Notation\n",
    "\n",
    "To start off:\n",
    "* A particular layer of a neural net will be denoted as $l$. $l-1$, $l+1$, etc. refer to the layers before or after layer $l$, and $L$ denotes the final (output) layer.\n",
    "* Assuming we've passed some value through the net, $a_j^l$ is the activation value of the $j$th neuron in layer $l$ (the output of the activation function). $z_j^l$ is the pre-activation value, that is, the weighted sum of the inputs from the previous layer plus the bias (so $a_j^l = \\sigma(z_j^l)$ where $\\sigma$ is that neuron's activation function. We can also refer to $a^l$, $b^l$, or $z^l$ to denote the vector of the given quantities for layer $l$ (e.g. $a^l = [a_0^l, ..., a_n^l]$, where layer $l$ has $n$ neurons total).\n",
    "* $w_{jk}^l$ is the current weight from neuron $k$ in layer $l-1$ to neuron $j$ in layer $l$ (i.e. $w_{jk}^l$ is the weight *to* $j$ *from* $k$. (This is backwards for reasons that make more sense when you think of a neural net as a list of weight matrices and bias vectors,  but we'll use this convention to abide by historical precedent.) $b_j^l$ is the current bias for neuron $j$ in layer $l$.\n",
    "\n",
    "To train a neural net, we have some set of input values that are paired with the corresponding desired output values. We also have a cost function of some kind that provides a measure of the difference between the desired output and the actual output of the neural net.\n",
    "\n",
    "* If our net has $n$ neurons in the input layer and $m$ in the output layer, then $(x, y)$ is a training example, where $x$ is a vector of length $n$ and $y$ is a vector of length $m$.\n",
    "* If we feed a training input $x$ through the network, we get some output vector $a^L$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49556c",
   "metadata": {},
   "source": [
    "### The cost function\n",
    "\n",
    "Our set of training examples is fixed; we're trying to change all the weights and biases in the network so that overall, $a^L$ for each $x$ is pretty close to the corresponding $y$. So at a high level, think of the cost function as something that takes a bunch of candidate values for each weight and bias, applies those weights and biases to each training example, and outputs some measure of the cumulative cost. We want to find some particular set of weights and biases that minimizes the cumulative cost. Our cost function is not a function $C(y, a^L)$ for particular examples; it's more like a function $C_T(w^L, w^{L-1}, ..., w^0, b^L, b^{L-1}, ..., b^0)$, parameterized by the training set $T$ and varying over the weights and biases. This is why it makes sense to talk about minimizing the cost by changing them - it's a function of those quantities and we can do calculus to it.\n",
    "\n",
    "The overall cost function $C$ measures some cumulative error over a bunch of training examples. For backpropagation, though, we want to be able to see how the net processes individual examples, so we can figure out how the net needs to change to better suit each one. So we want our overall cost function to be easily decomposable into a cost function for a particular example - call this $C_x$. So without explicitly defining our cost function, we're going to impose a few restrictions on it:\n",
    "\n",
    "* $C_T(w, b) = \\frac{\\epsilon}{|{T}|}\\sum_{(x, y) \\in T}C_x(w, b)$, that is, for a particular combo of weights and biases, $C_T$ is the average of individual errors $C_x$ over all pairs in the training set, maybe scaled by some constant $\\epsilon$ depending on the exact form.\n",
    "* $C_x(w, b)$ can be expressed as a function of the final outputs of the network $a_0^L, ..., a_n^L$ (which are themselves functions of the weights and biases).\n",
    "* $C_x(w, b)$ should be easily differentiable with respect to $a_0^L, ..., a_n^L$. We want to minimize $C_T$, which means we're going to be taking derivatives with respect to each weight and bias, and in this form the derivative of  $C_T$ works out to the (scaled) average of the derivatives of all the individual $C_x$s. (I'm handwaving a bit here by conflating weights/biases with network outputs, but $C_x$ is basically a nasty composition of functions that we'll deconstruct using the chain rule - you can think of it as $C_x(a^L(w, b))$ if it makes this clearer. I promise the math works out.)\n",
    "\n",
    "Depending on the source, there various names for $C_T$ and $C_x$, e.g. $C_T$ is the cost function, each $C_x$ is a loss function, $C_T$ is the objective function, $C_x$ is an error function, etc. I'm arbitrarily using \"cost function\" for both $C_T$ and $C_x$ and using the subscript to differentiate between the overall and the particular version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78461303",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "We ultimately want to find the gradient of the overall cost function $\\nabla C_T$, which is just shorthand for the vector of partial derivatives $\\frac{\\partial C_T}{\\partial w_{jk}^l}$ and $\\frac{\\partial C_T}{\\partial b_{j}^l}$ for all layers $l$ and connected neurons $j \\in l$, $k \\in l - 1$ in the network. To do that, we need to calculate the gradient vector $\\nabla C_x$ for each example $x \\in T$, take the elementwise average of those individual gradients as $\\nabla C_T$, and then adjust each weight and bias in the network based on its respective partial derivative: if $\\frac{\\partial C_T}{\\partial w_{jk}^l}$ is positive, then $C_T$ is increasing in tandem with $w_{jk}^l$, so we should decrease $w_{jk}^l$ to move down the slope towards the minimum. The reverse applies when $\\frac{\\partial C_T}{\\partial w_{jk}^l}$ is negative. The exact step size should be proportional to the size of $\\frac{\\partial C_T}{\\partial w_{jk}^l}$ - if the slope is very steep, we can take a larger step and still be confident that we'll hit some lower point; if the slope is very shallow, we want to move more slowly to avoid overshooting the minimum. (As mentioned above, all this assumes that $C_T$ is reasonably well-behaved.)\n",
    "\n",
    "So backpropagation boils down to something pretty straightforward: how do we efficiently calculate $\\nabla C_x$ for a training example $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e413e67",
   "metadata": {},
   "source": [
    "### Backpropagation in four easy steps\n",
    "\n",
    "__Goal:__ Expressions for $\\frac{\\partial C_x}{\\partial w_{jk}^l}$ and $\\frac{\\partial C_x}{\\partial b_j^l}$ for all weights $w_{jk}^l$ and biases $b_j^l$.\n",
    "\n",
    "__Definition:__ Let $\\delta_j^l \\equiv \\frac{\\partial C_x}{\\partial z_j^l}$, where $z_j^l$ is the pre-activation value of the $j$th neuron in layer $l$ on training input $x$. We can think of the quantity $\\delta_j^l$ as the _error_ of that neuron: the larger the quantity, the more we can potentially change the  value of $C_x$ by tweaking $z_j^l$, and vice versa. Let $\\delta^l$ be the vector of per-neuron errors for layer $l$, that is, $\\delta^l = [\\delta_0^l, ..., \\delta_n^l]$.\n",
    "\n",
    "__(1)__ $\\delta_j^L = \\frac{\\partial C_x}{\\partial a_j^L}\\sigma'(z_j^L)$\n",
    "\n",
    "__Proof of (1):__ Since $C_x$ actually takes $a_j^L = \\sigma(z_j^L)$ as a parameter, we can rewrite this expression using the chain rule:\n",
    "\n",
    "$$\\delta_j^L \\equiv \\frac{\\partial C_x}{\\partial z_j^L} = \\sum_{k\\in L}\\frac{\\partial C_x}{\\partial a_k^L}\\frac{\\partial a_k^L}{\\partial z_j^L}$$\n",
    "\n",
    "Note that $\\frac{\\partial a_k^L}{\\partial z_j^L} = 0$ for $k \\neq j$ (since the activation value at each neuron $a_k^l$ depends only on the pre-activation value at the same neuron $z_k^l$, not on any others). Thus we can write \n",
    "\n",
    "$$ \\sum_{k\\in L}\\frac{\\partial C_x}{\\partial a_k^L}\\frac{\\partial a_k^L}{\\partial z_j^L} = \\frac{\\partial C_x}{\\partial a_j^L} \\frac{\\partial a_j^L}{\\partial z_j^L}$$\n",
    "\n",
    "$$ = \\frac{\\partial C_x}{\\partial a_j^L}\\frac{\\mathop{d}}{\\mathop{dz_j^L}}(\\sigma(z_j^l)) $$\n",
    "\n",
    "$$ = \\frac{\\partial C_x}{\\partial a_j^L}\\sigma'(z_j^l). $$\n",
    "\n",
    "Per the discussion above, we can safely assume that $\\frac{\\partial C_x}{\\partial a_j^L}$ (the partial derivative of $C_x$ with respect to the $j$th output) is easily stated (e.g. when $C_T$ is the mean squared error cost function, we have $C_x = \\frac{1}{2}\\sum_{j}(a_j^L - y_j)^2$, so $\\frac{\\partial C_x}{\\partial a_j^L} = a_j^L - y_j$). Similarly, any standard activation function $\\sigma$ will have an easily expressed $\\sigma'$.\n",
    "\n",
    "__(2)__ $\\delta_j^l = \\sigma'(z_j^l) (w^{l+1})^\\intercal[j] \\cdot \\delta^{l+1} $\n",
    "\n",
    "__Proof of (2):__ As above, we rewrite using the chain rule, this time using $z_k^{l+1}$ as the intermediate variable.\n",
    "\n",
    "$$\\delta_j^l \\equiv \\frac{\\partial C_x}{\\partial z_j^l} = \\sum_{k \\in l + 1}\\frac{\\partial C_x}{\\partial z_k^{l + 1}}\\frac{\\partial z_k^{l+1}}{\\partial z_j^l}$$\n",
    "\n",
    "$$ = \\sum_{k \\in l + 1}\\delta_k^{l + 1}\\frac{\\partial z_k^{l+1}}{\\partial z_j^l} \\text{ (by definition)} $$\n",
    "\n",
    "$$ = \\sum_{k \\in l + 1}\\delta_k^{l + 1}\\frac{\\mathop{d}}{\\mathop{dz_j^l}}[\\sum_{i \\in l}w_{ki}^{l+1}\\sigma(z_i^l) + b_k^{l+1}],$$\n",
    "\n",
    "explicitly expanding the quantity $z_k^{l+1}$ as the weighted sum of inputs to neuron $k$ in layer $l+1$ from the neurons in layer $l$ (indexed by $i$) plus the bias $b_k^{l+1}$.\n",
    "\n",
    "Taking the derivative of this sum with respect to $z_j^l$ yields\n",
    "\n",
    "$$ = \\sum_{k \\in l + 1}\\delta_k^{l + 1}(w_{kj}^{l+1}\\sigma'(z_j^l)) $$\n",
    "\n",
    "$$ = \\sigma'(z_j^l)\\sum_{k \\in l + 1}w_{kj}^{l+1}\\delta_k^{l + 1} $$\n",
    "\n",
    "$$ = \\sigma'(z_j^l) (w^{l+1})^\\intercal[j] \\cdot \\delta^{l+1},$$\n",
    "\n",
    "where $(w^{l+1})^\\intercal[j]$ denotes the $j$th row of the transposed weight matrix, that is, a row vector $[w_0j^{l+1}, ..., w_nj^{l+1}]$ containing the weights from neuron $j$ in layer $l$ to each of the $n$ neurons in layer $l + 1$, that is, we're just rewriting the summation in the previous line as a dot product of two length-$n$ vectors.\n",
    "\n",
    "We can get a more elegant expression by generalizing over $j$ and instead writing\n",
    "\n",
    "$$ \\delta^l = (w^{l+1})^\\intercal \\delta^{l+1} \\times \\sigma'(z^l), $$\n",
    "\n",
    "where $\\times$ indicates elementwise multiplication and $\\sigma'(z^l) = [\\sigma(z_0^l), ..., \\sigma(z_m^l)]$.\n",
    "\n",
    "By taking (1) as our base case, we can iteratively take (2) to find $\\delta^l$ for all layers $l$.\n",
    "\n",
    "__(3)__ $\\frac{\\partial C_x}{\\partial b_j^l} = \\delta_j^l$\n",
    "\n",
    "__Proof of (3):__ Expand using the chain rule again to get a $\\delta$-term, and simplify the remainder:\n",
    "\n",
    "$$ \\frac{\\partial C_x}{\\partial b_j^l} = \\sum_{k \\in l}\\frac{\\partial C_x}{\\partial z_k^l} \\frac{\\partial z_k^l}{\\partial b_j^l}$$\n",
    "\n",
    "$$ = \\sum_{k \\in l}\\delta_k^l \\frac{\\partial z_k^l}{\\partial b_j^l}$$\n",
    "\n",
    "$$ = \\delta_j^l \\frac{\\partial z_j^l}{\\partial b_j^l},$$\n",
    "\n",
    "since $z_k^l$ is only affected by $b_j^l$ when $k = j$ (the bias at neuron $j$ does not factor into any of the other neurons in the layer), so all other terms in this sum go to zero. Continuing, expand quantity $z_j^l$ to get\n",
    "\n",
    "$$ = \\delta_j^l \\frac{\\mathop{d}}{\\mathop{db_j^l}}(w^l[j] \\cdot a^{l-1}) + b_j^l) $$\n",
    "\n",
    "$$ = \\delta_j^l.$$\n",
    "\n",
    "This is basically a consequence of the fact that the bias is just a constant term, so changing the bias by some quantity has exactly the same impact as changing the pre-activation quantity $z$ by the same amount after calculating it, so the derivative is the same with respect to either one.\n",
    "\n",
    "__(4)__ $\\frac{\\partial C_x}{\\partial w_{jk}^l} = a_k^{l-1} \\delta_j^l$\n",
    "\n",
    "__Proof of (4):__ Chain rule again.\n",
    "\n",
    "$$ \\frac{\\partial C_x}{\\partial w_{jk}^l} = \\sum_{i \\in l} \\frac{\\partial C_x}{\\partial z_i^l} \\frac{\\partial z_i^l}{\\partial w_{jk}^l} $$\n",
    "\n",
    "$$ = \\frac{\\partial C_x}{\\partial z_j^l} \\frac{\\partial z_j^l}{\\partial w_{jk}^l}, $$\n",
    "\n",
    "again eliminating most of the summation by noting that the weight to $k$ in $l$ from $j$ in $l-1$ only affects $z_i^l$ when $i=j$. Continuing,\n",
    "\n",
    "$$ = \\delta_j^l \\frac{\\mathop{d}}{\\mathop{dw_{jk}^l}}(w_{j0}^l a_0^{l-1} + ... + w_{jk}^l a_k^{l-1} + ... + w_{jn}^l a_n^{l-1} + b_j^l) $$\n",
    "\n",
    "$$ = \\delta_j^l a_k^{l-1}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff2e65",
   "metadata": {},
   "source": [
    "### So:\n",
    "\n",
    "Every time we pass an input $x$ forward through our network, we calculate $z^l$ and $a^l$ for each layer. Then we can use (1) and (2) to propagate error backwards to find $\\delta^l$ for each layer, and then in turn use (3) and (4) to calculate $\\frac{\\partial C_x}{\\partial w_jk^l}$ and $\\frac{\\partial C_x}{\\partial b_j^l}$ for each weight in bias in terms of the associated errors. This gives us the desired gradient $\\nabla C_x$. Then we just do this for a bunch of different $x$s and take the elementwise average of all the resulting  $\\nabla C_x$s to get $\\nabla C_T$. Then we tweak the weights and biases based on that and start the whole process again until we decide to stop. That's it. The individual calculations end up being pretty simple, which kinda makes sense when you consider that the net is basically a nest of linear combinations (excluding the activation functions, but again, those derivatives are pretty straightforward.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98edb98",
   "metadata": {},
   "source": [
    "### Implementation v1\n",
    "\n",
    "I've sort of kneecapped myself here by modeling my net as a graph with weighted edges instead of a set of matrices and bias vectors. In the interest of, I guess, masochism, I'm gonna try and implement the world's slowest backpropagation process. Putting the existing code below so that each notebook is self-contained. One issue with the original code is that there's no simple way to access the derivative of the activation function for a given neuron, so we'll bundle both functions together in a new wrapper and tweak the Neuron class slightly to reflect the new definition. We'll also add an additional field to each Neuron to track pre-activation value separately from activation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83b2178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Activation(object):\n",
    "    def __init__(self, f, f_prime):\n",
    "        self.f = f\n",
    "        self.f_prime = f_prime\n",
    "\n",
    "    def activate(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "    def deriv(self, x):\n",
    "        return self.f_prime(x)\n",
    "\n",
    "def identity_f(x):\n",
    "    return x\n",
    "def identity_fprime(x):\n",
    "    return 1\n",
    "identity = Activation(identity_f, identity_fprime)\n",
    "\n",
    "def sigmoid_f(x):\n",
    "    return 1 / (1 + math.e ** (-x))\n",
    "def sigmoid_fprime(x):\n",
    "    return sigmoid_f(x) * (1 - sigmoid_f(x))\n",
    "sigmoid = Activation(sigmoid_f, sigmoid_fprime)\n",
    "\n",
    "activation_types = {\n",
    "    \"identity\": identity,\n",
    "    \"sigmoid\": sigmoid,\n",
    "}\n",
    "\n",
    "class Neuron(object):\n",
    "    \n",
    "    # Initialize with an activation function\n",
    "    # Bias, weights, and links will be determined later\n",
    "    def __init__(self, f, b):\n",
    "        self.activation = f\n",
    "        self.bias = b\n",
    "        self.upstream_neurons = []\n",
    "        self.upstream_weights = []\n",
    "        self.downstream_neurons = []\n",
    "        self.downstream_weights = []\n",
    "        self.pre_activation_value = None\n",
    "        self.activation_value = None\n",
    "\n",
    "    # Link from an earlier neuron\n",
    "    # Input array and weight array are paired\n",
    "    def link_input(self, input_neuron, weight):\n",
    "        self.upstream_neurons.append(input_neuron)\n",
    "        self.upstream_weights.append(weight)\n",
    "        input_neuron.downstream_neurons.append(self)\n",
    "        input_neuron.downstream_weights.append(weight)\n",
    "\n",
    "    # Link to a later neuron\n",
    "    # Should use one or the other of the link functions for any given net\n",
    "    # to avoid double binding neurons\n",
    "    def link_output(self, output_neuron, weight):\n",
    "        self.downstream_neurons.append(output_neuron)\n",
    "        self.downstream_weights.append(weight)\n",
    "        output_neuron.upstream_neurons.append(self)\n",
    "        output_neuron.upstream_weights.append(weight)\n",
    "        \n",
    "    def set_bias(self, b):\n",
    "        self.bias = b\n",
    "        \n",
    "    def set_initial_value(self, v):\n",
    "        self.activation_value = v\n",
    "        \n",
    "    def activate(self):\n",
    "        total = 0\n",
    "        for i in range(len(self.upstream_neurons)):\n",
    "            neuron = self.upstream_neurons[i]\n",
    "            weight = self.upstream_weights[i]\n",
    "            total += neuron.activation_value * weight\n",
    "        total += self.bias\n",
    "        self.pre_activation_value = total\n",
    "        total = self.activation.activate(total)\n",
    "        self.activation_value = total\n",
    "\n",
    "\n",
    "class NeuralNet(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.input_size = 0\n",
    "        self.output_size = 0\n",
    "        self.n_layers = 0\n",
    "\n",
    "    def add_layer(self, n, f):\n",
    "        self.layers.append([Neuron(f, 0) for _ in range(n)])\n",
    "\n",
    "    def fully_connect_layers(self, l1, l2, weights):\n",
    "        for i in range(len(l1)):\n",
    "            for j in range(len(l2)):\n",
    "                input_neuron = l1[i]\n",
    "                output_neuron = l2[j]\n",
    "                weight = weights[j][i]\n",
    "                input_neuron.link_output(output_neuron, weight)\n",
    "\n",
    "    # Spec of the format [(\"identity|sigmoid|tanh|relu\", n)]\n",
    "    # Initialize a neural net with all weights 1 and all biases 0 \n",
    "    def build_from_spec(self, spec):\n",
    "        for (activation, n) in spec:\n",
    "            if activation not in activation_types:\n",
    "                print(f\"Unrecognized activation function: {activation}\")\n",
    "                return\n",
    "            ac = activation_types[activation]\n",
    "            self.add_layer(n, ac)\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            l1 = self.layers[i]\n",
    "            l2 = self.layers[i + 1]\n",
    "            n = len(l1)\n",
    "            m = len(l2)\n",
    "            weights = [[1 for _ in range(n)] for _ in  range(m)]\n",
    "            self.fully_connect_layers(l1, l2, weights)\n",
    "        self.input_size = len(self.layers[0])\n",
    "        self.output_size = len(self.layers[-1])\n",
    "        self.n_layers =  len(self.layers)\n",
    "\n",
    "\n",
    "    # input_vector is just a list-like object that can be indexed\n",
    "    def passthrough(self, input_vector):\n",
    "        if len(input_vector) != self.input_size:\n",
    "            print(f\"Mismatched input: expected size {self.input_size} but got size {len(input_vector)}\")\n",
    "        for i in range(self.input_size):\n",
    "            self.layers[0][i].set_initial_value(input_vector[i])\n",
    "        for layer in self.layers[1:]:\n",
    "            for neuron in layer:\n",
    "                neuron.activate()\n",
    "        output_vector = [neuron.activation_value for neuron in self.layers[-1]]\n",
    "        return output_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7843183",
   "metadata": {},
   "source": [
    "I'm planning to use the classic iris dataset to train and validate my network implementation - if you haven't encountered it, it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75d1982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepallength,sepalwidth,petallength,petalwidth,class\n",
      "\n",
      "5.1,3.5,1.4,0.2,Iris-setosa\n",
      "\n",
      "7.0,3.2,4.7,1.4,Iris-versicolor\n",
      "\n",
      "6.3,3.3,6.0,2.5,Iris-virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"../datasets/iris.csv\")\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "print(lines[0])\n",
    "print(lines[1])\n",
    "print(lines[51])\n",
    "print(lines[101])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e80e2",
   "metadata": {},
   "source": [
    "So 4 features and 3 categories, which determines the input and output layers for our network. Let's start small for now, with a single hidden layer of 5 neurons (chosen pretty much randomly). Realistically the final layer should be a softmax or something but for now we'll leave it as a sigmoid and plan on hooking up some extra machinery that tells us what the highest prediction was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "909d4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_net = NeuralNet()\n",
    "iris_net.build_from_spec([(\"identity\", 4), (\"sigmoid\", 5), (\"sigmoid\", 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ea4492",
   "metadata": {},
   "source": [
    "Now we have to implement:\n",
    "* an overall cost function\n",
    "* an individual cost function (and derivative)\n",
    "* equations (1) through (4)\n",
    "* a function that hooks all of these together\n",
    "\n",
    "Starting off, I'm just going to use mean squared error for the cost function, and consquently squared error for the individual cost function. If I wanted to make the distinction between \"parameters\" (x, y) and \"variables\" (ws, bs) extremely clear, these could be functions that first take a training set or training example and return a new parameterized function that takes a net, but frankly that's a bit much even for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a6b2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = training set of the form [(x, y)]\n",
    "def mse(t):\n",
    "    total_error = 0\n",
    "    for (x, y) in t:\n",
    "        total_error += squared_error(x, y, net)\n",
    "    return total_error / len(t)\n",
    "\n",
    "def squared_error(x, y, net):\n",
    "    a = net.passthrough(x)\n",
    "    return 0.5 * sum([(a[i] - y[i])**2 for i in range(len(a))])\n",
    "\n",
    "def squared_error_prime(aL, y):\n",
    "    return [aL[i] - y[i] for i in range(len(aL))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c83e9",
   "metadata": {},
   "source": [
    "Now the general math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f81b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and y are a training example\n",
    "# cost_x_prime is an arbitary single-example cost function derivative \n",
    "# that takes an output vector a^L and an expected vector y\n",
    "def final_layer_error(net, x, y, cost_x_prime):\n",
    "    aL = net.passthrough(x)\n",
    "    dC_da = cost_x_prime(aL, y)\n",
    "    sigma_prime_zL = [neuron.activation.deriv(neuron.pre_activation_value) for neuron in net.layers[-1]]\n",
    "    deltaL = [dC_da[i] * sigma_prime_zL[i] for i in range(len(dC_da))]\n",
    "    return deltaL\n",
    "\n",
    "def layer_error(net, x, y, cost_x_prime):\n",
    "    deltaL = final_layer_error(net, x, y, cost_x_prime)\n",
    "    error_vectors = [deltaL]\n",
    "    for l in range(2, net.n_layers):\n",
    "        layer = net.layers[-l]  # start with layers[-2], work back to layers[-n_layers + 1]\n",
    "        # First layer does not have an error associated with it because it doesn't have input weights\n",
    "        weights_transpose = [neuron.downstream_weights for neuron in layer]\n",
    "        next_delta = error_vectors[0]\n",
    "        weight_delta_product = []\n",
    "        for weights in weights_transpose:\n",
    "            weight_delta_product.append(sum([weights[i] * next_delta[i] for i in range(len(next_delta))]))\n",
    "        sigma_prime_zl = [neuron.activation.deriv(neuron.pre_activation_value) for neuron in layer]\n",
    "        deltal = [weight_delta_product[i] * sigma_prime_zl[i] for i in range(len(sigma_prime_zl))]\n",
    "        error_vectors = [deltal] + error_vectors\n",
    "    return error_vectors\n",
    "\n",
    "def bias_gradient(net, error_vectors):\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e2785c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.893115758926319e-07,\n",
       "  4.893115758926319e-07,\n",
       "  4.893115758926319e-07,\n",
       "  4.893115758926319e-07,\n",
       "  4.893115758926319e-07],\n",
       " [-4.4510827315210804e-05, 0.006604764921594382, 0.006604764921594382]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [5.1,3.5,1.4,0.2]\n",
    "y = [1, 0, 0]\n",
    "layer_error(iris_net, x, y, squared_error_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2514b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "𝛿𝑙=(𝑤𝑙+1)⊺𝛿𝑙+1×𝜎′(𝑧𝑙)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
