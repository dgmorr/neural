{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325bbd80",
   "metadata": {},
   "source": [
    "# 1b. Backpropagation\n",
    "\n",
    "So I spent the past week and a half convincing myself that I understand the math behind backpropagation, and now I'm going to first prove it all over again here, and then implement it for my baby neural net, so that I can start training it. \n",
    "\n",
    "I'm following along with [Nielsen Chapter 2](http://neuralnetworksanddeeplearning.com/chap2.html), which I really can't praise highly enough - if you don't currently have access to an ML professor who can walk you through the math in person, this chapter is a good substitute. Now that I've gone through it several times and written out my own proofs of various parts, I'm going to try to explain/implement this without referring back to the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfbb8c",
   "metadata": {},
   "source": [
    "### A brief refresher on gradient descent\n",
    "\n",
    "The basic idea behind training a neural net is that we start with random weights and biases, and want to move towards values for the weights and biases that give us the best performance on our set of training data. Let's unpack this:\n",
    "* __training data:__ this is supervised learning; we've got a bunch of input values along with the expected outputs, and we're trying to have the net arrive at some generalized relationship between them that will hold true for new data. In practice, there are a lot different methodologies for how to use your training data, which I'll get into in more detail in the next journal when I actually start training my neural net.\n",
    "* __performance:__ some measure of how well the net does relative to the expected outputs of the training data -  how frequently is it right (on a classification-type problem), how close is it on average (on an estimation-type problem), etc. Performance on a training set is measured by some cost function that aggregates from performance on each example.\n",
    "* __best:__ not necessarily 100% accurate (since that's probably overfitting and won't generalize well), but reasonably good, depending on what problem we're dealing with and how accurate we need to be.\n",
    "* __move towards values for the weights and biases:__ we're trying to minimize the cost function, that is, find the set of weights and biases that produces the minimum cost for our training data. However, there's not a simple closed-form expression that lets us directly calculate the weights and biases that will lead to a global minimum - there are dozens of weight/bias variables involved even in a small neural net. What we can do instead is find the derivative at our current set of weights and biases, in the form of a partial derivative for each weight and bias individually. Then, assuming the cost function is reasonably well-behaved, we can take a small step \"downhill\" for each variable, which should bring us a bit closer overall to a minimum (and a global minimum if we're very lucky, but that doesn't really matter). The general method at work here is gradient descent; backpropagation is an algorithm for efficiently calculating the necessary gradient for a neural net."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ecb28",
   "metadata": {},
   "source": [
    "### Notation\n",
    "\n",
    "To start off:\n",
    "* A particular layer of a neural net will be denoted as $l$. $l-1$, $l+1$, etc. refer to the layers before or after layer $l$, and $L$ denotes the final (output) layer.\n",
    "* Assuming we've passed some value through the net, $a_j^l$ is the activation value of the $j$th neuron in layer $l$ (the output of the activation function). $z_j^l$ is the pre-activation value, that is, the weighted sum of the inputs from the previous layer plus the bias (so $a_j^l = \\sigma(z_j^l)$ where $\\sigma$ is that neuron's activation function. We can also refer to $a^l$, $b^l$, or $z^l$ to denote the vector of the given quantities for layer $l$ (e.g. $a^l = [a_0^l, ..., a_n^l]$, where layer $l$ has $n$ neurons total).\n",
    "* $w_{jk}^l$ is the current weight from neuron $k$ in layer $l-1$ to neuron $j$ in layer $l$ (i.e. $w_{jk}^l$ is the weight *to* $j$ *from* $k$. (This is backwards for reasons that make more sense when you think of a neural net as a list of weight matrices and bias vectors,  but we'll use this convention to abide by historical precedent.) $b_j^l$ is the current bias for neuron $j$ in layer $l$.\n",
    "\n",
    "To train a neural net, we have some set of input values that are paired with the corresponding desired output values. We also have a cost function of some kind that provides a measure of the difference between the desired output and the actual output of the neural net.\n",
    "\n",
    "* If our net has $n$ neurons in the input layer and $m$ in the output layer, then $(x, y)$ is a training example, where $x$ is a vector of length $n$ and $y$ is a vector of length $m$.\n",
    "* If we feed a training input $x$ through the network, we get some output vector $a^L$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49556c",
   "metadata": {},
   "source": [
    "### The cost function\n",
    "\n",
    "Our set of training examples is fixed; we're trying to change all the weights and biases in the network so that overall, $a^L$ for each $x$ is pretty close to the corresponding $y$. So at a high level, think of the cost function as something that takes a bunch of candidate values for each weight and bias, applies those weights and biases to each training example, and outputs some measure of the cumulative cost. We want to find some particular set of weights and biases that minimizes the cumulative cost. Our cost function is not a function $C(y, a^L)$ for particular examples; it's more like a function $C_T(w^L, w^{L-1}, ..., w^0, b^L, b^{L-1}, ..., b^0)$, parameterized by the training set $T$ and varying over the weights and biases. This is why it makes sense to talk about minimizing the cost by changing them - it's a function of those quantities and we can do calculus to it.\n",
    "\n",
    "The overall cost function $C$ measures some cumulative error over a bunch of training examples. For backpropagation, though, we want to be able to see how the net processes individual examples, so we can figure out how the net needs to change to better suit each one. So we want our overall cost function to be easily decomposable into a cost function for a particular example - call this $C_x$. So without explicitly defining our cost function, we're going to impose a few restrictions on it:\n",
    "\n",
    "* $C_T(w, b) = \\frac{\\epsilon}{|{T}|}\\sum_{(x, y) \\in T}C_x(w, b)$, that is, for a particular combo of weights and biases, $C_T$ is the average of individual errors $C_x$ over all pairs in the training set, maybe scaled by some constant $\\epsilon$ depending on the exact form.\n",
    "* $C_x(w, b)$ can be expressed as a function of the final outputs of the network $a_0^L, ..., a_n^L$ (which are themselves functions of the weights and biases).\n",
    "* $C_x(w, b)$ should be easily differentiable with respect to $a_0^L, ..., a_n^L$. We want to minimize $C_T$, which means we're going to be taking derivatives with respect to each weight and bias, and in this form the derivative of  $C_T$ works out to the (scaled) average of the derivatives of all the individual $C_x$s. (I'm handwaving a bit here by conflating weights/biases with network outputs, but $C_x$ is basically a nasty composition of functions that we'll deconstruct using the chain rule - you can think of it as $C_x(a^L(w, b))$ if it makes this clearer. I promise the math works out.)\n",
    "\n",
    "Depending on the source, there various names for $C_T$ and $C_x$, e.g. $C_T$ is the cost function, each $C_x$ is a loss function, $C_T$ is the objective function, $C_x$ is an error function, etc. I'm arbitrarily using \"cost function\" for both $C_T$ and $C_x$ and using the subscript to differentiate between the overall and the particular version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf78e7",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "We ultimately want to find the gradient of the overall cost function $\\nabla C_T$, which is just shorthand for the vector of partial derivatives $\\frac{\\partial C_T}{\\partial w_{jk}^l}$ and $\\frac{\\partial C_T}{\\partial b_{j}^l}$ for all layers $l$ and connected neurons $j \\in l$, $k \\in l - 1$ in the network. To do that, we need to calculate the gradient vector $\\nabla C_x$ for each example $x \\in T$, take the elementwise average of those individual gradients as $\\nabla C_T$, and then adjust each weight and bias in the network based on its respective partial derivative: if $\\frac{\\partial C_T}{\\partial w_{jk}^l}$ is positive, then $C_T$ is increasing in tandem with $w_{jk}^l$, so we should decrease $w_{jk}^l$ to move down the slope towards the minimum. The reverse applies when $\\frac{\\partial C_T}{\\partial w_{jk}^l}$ is negative. The exact step size should be proportional to the size of $\\frac{\\partial C_T}{\\partial w_{jk}^l}$ - if the slope is very steep, we can take a larger step and still be confident that we'll hit some lower point; if the slope is very shallow, we want to move more slowly to avoid overshooting the minimum. (As mentioned above, all this assumes that $C_T$ is reasonably well-behaved.)\n",
    "\n",
    "So backpropagation boils down to something pretty straightforward: how do we efficiently calculate $\\nabla C_x$ for a training example $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e413e67",
   "metadata": {},
   "source": [
    "### Backpropagation in four easy steps\n",
    "\n",
    "__Goal:__ Expressions for $\\frac{\\partial C_x}{\\partial w_{jk}^l}$ and $\\frac{\\partial C_x}{\\partial b_j^l}$ for all weights $w_{jk}^l$ and biases $b_j^l$.\n",
    "\n",
    "__Definition:__ Let $\\delta_j^l \\equiv \\frac{\\partial C_x}{\\partial z_j^l}$, where $z_j^l$ is the pre-activation value of the $j$th neuron in layer $l$ on training input $x$. We can think of the quantity $\\delta_j^l$ as the _error_ of that neuron: the larger the quantity, the more we can potentially change the  value of $C_x$ by tweaking $z_j^l$, and vice versa. Let $\\delta^l$ be the vector of per-neuron errors for layer $l$, that is, $\\delta^l = [\\delta_0^l, ..., \\delta_n^l]$.\n",
    "\n",
    "__(1)__ $\\delta_j^L = \\frac{\\partial C_x}{\\partial a_j^L}\\sigma'(z_j^L)$\n",
    "\n",
    "__Proof of (1):__ Since $C_x$ actually takes $a_j^L = \\sigma(z_j^L)$ as a parameter, we can rewrite this expression using the chain rule:\n",
    "\n",
    "$$\\frac{\\partial C_x}{\\partial z_j^L} = \\sum_{k\\in L}\\frac{\\partial C_x}{\\partial a_k^L}\\frac{\\partial a_k^L}{\\partial z_j^L}$$\n",
    "\n",
    "Note that $\\frac{\\partial a_k^L}{\\partial z_j^L} = 0$ for $k \\neq j$ (since the activation value at each neuron $a_k^l$ depends only on the pre-activation value at the same neuron $z_k^l$, not on any others). Thus we can write \n",
    "\n",
    "$$ \\sum_{k\\in L}\\frac{\\partial C_x}{\\partial a_k^L}\\frac{\\partial a_k^L}{\\partial z_j^L} = \\frac{\\partial C_x}{\\partial a_j^L} \\frac{\\partial a_j^L}{\\partial z_j^L}$$\n",
    "\n",
    "$$ = \\frac{\\partial C_x}{\\partial a_j^L}\\frac{\\mathop{d}}{\\mathop{dz_j^L}}(\\sigma(z_j^l)) $$\n",
    "\n",
    "$$ = \\frac{\\partial C_x}{\\partial a_j^L}\\sigma'(z_j^l). $$\n",
    "\n",
    "Per the discussion above, we can safely assume that $\\frac{\\partial C_x}{\\partial a_j^L}$ (the partial derivative of $C_x$ with respect to the $j$th output) is easily stated (e.g. when $C_T$ is the mean squared error cost function, we have $C_x = \\frac{1}{2}\\sum_{j}(a_j^L - y_j)^2$, so $\\frac{\\partial C_x}{\\partial a_j^L} = a_j^L - y_j$). Similarly, any standard activation function $\\sigma$ will have an easily expressed $\\sigma'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a440e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
